{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gesture Recognition\n",
    "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started. Once you have completed the code you can download the notebook for making a submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "import datetime\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the random seed so that the results don't vary drastically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "import random as rn\n",
    "rn.seed(30)\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this block, you read the folder names for training and validation. You also set the `batch_size` here. Note that you set the batch size in such a way that you are able to use the GPU in full capacity. You keep increasing the batch size until the machine throws an error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**data path: /home/datasets/Project_data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_doc = np.random.permutation(open('/home/datasets/Project_data/train.csv').readlines())\n",
    "val_doc = np.random.permutation(open('/home/datasets/Project_data/val.csv').readlines())\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator\n",
    "This is one of the most important part of the code. The overall structure of the generator has been given. In the generator, you are going to preprocess the images as you have images of 2 different dimensions as well as create a batch of video frames. You have to experiment with `img_idx`, `y`,`z` and normalization such that you get high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(source_path, folder_list, batch_size):\n",
    "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
    "    img_idx = np.arange(0,30,2) # choosing every alternative image\n",
    "    while True:\n",
    "        t = np.random.permutation(folder_list)\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            batch_data = np.zeros((batch_size,len(img_idx),120,120,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(batch_size): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    # Crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    # and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image,(120,120))\n",
    "                    \n",
    "                    # Normalise and feed in the image\n",
    "                    image = image - np.percentile(image,5)/ (np.percentile(image,95) - np.percentile(image,5))\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = image[:,:,0]\n",
    "                    batch_data[folder,idx,:,:,1] = image[:,:,1]\n",
    "                    batch_data[folder,idx,:,:,2] = image[:,:,2]\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels #you yield the batch_data and the batch_labels, remember what does yield do\n",
    "\n",
    "        \n",
    "        # Remaining data points which are left after full batches\n",
    "        rem_image = len(folder_list)%batch_size\n",
    "        batch += 1\n",
    "        if(rem_image!=0):\n",
    "            batch_data = np.zeros((rem_image,len(img_idx),120,120,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
    "            batch_labels = np.zeros((rem_image,5)) # batch_labels is the one hot representation of the output\n",
    "            for folder in range(rem_image): # iterate over the batch_size\n",
    "                imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
    "                for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
    "                    image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
    "                    \n",
    "                    # Crop the images and resize them. Note that the images are of 2 different shape \n",
    "                    # and the conv3D will throw error if the inputs in a batch have different shapes\n",
    "                    image = resize(image,(120,120))\n",
    "                    \n",
    "                    # Normalise and feed in the image\n",
    "                    image = image - np.percentile(image,5)/ (np.percentile(image,95) - np.percentile(image,5))\n",
    "                    \n",
    "                    batch_data[folder,idx,:,:,0] = image[:,:,0]\n",
    "                    batch_data[folder,idx,:,:,1] = image[:,:,1]\n",
    "                    batch_data[folder,idx,:,:,2] = image[:,:,2]\n",
    "                    \n",
    "                batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
    "            yield batch_data, batch_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note here that a video is represented above in the generator as (number of images, height, width, number of channels). Take this into consideration while creating the model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# training sequences = 663\n",
      "# validation sequences = 100\n",
      "# epochs = 15\n",
      "# num classes = 5\n"
     ]
    }
   ],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "train_path = '/home/datasets/Project_data/train'\n",
    "val_path = '/home/datasets/Project_data/val'\n",
    "num_train_sequences = len(train_doc)\n",
    "print('# training sequences =', num_train_sequences)\n",
    "num_val_sequences = len(val_doc)\n",
    "print('# validation sequences =', num_val_sequences)\n",
    "num_epochs = 15\n",
    "print ('# epochs =', num_epochs)\n",
    "num_classes = 5\n",
    "print ('# num classes =', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pre-setup\n",
    "Here you make the model using different functionalities that Keras provides. Remember to use `Conv3D` and `MaxPooling3D` and not `Conv2D` and `Maxpooling2D` for a 3D convolution model. You would want to use `TimeDistributed` while building a Conv2D + RNN model. Also remember that the last layer is the softmax. Design the network in such a way that the model is able to give good accuracy on the least number of parameters so that it can fit in the memory of the webcam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Conv3D, Dense, Dropout, GRU, Flatten, LSTM, MaxPooling2D, MaxPooling3D, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try to build different models each with different variations by adding/removing layers, fine tuning parameters, modifying the structure of the network, etc. to see how each one performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot model build history\n",
    "def plot(history):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,4))\n",
    "    axes[0].plot(history.history['loss'])   \n",
    "    axes[0].plot(history.history['val_loss'])\n",
    "    axes[0].legend(['loss','val_loss'])\n",
    "\n",
    "    axes[1].plot(history.history['categorical_accuracy'])   \n",
    "    axes[1].plot(history.history['val_categorical_accuracy'])\n",
    "    axes[1].legend(['categorical_accuracy','val_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create the `train_generator` and the `val_generator` which will be used in `.fit_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = generator(train_path, train_doc, batch_size)\n",
    "val_generator = generator(val_path, val_doc, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise callbacks to re-use\n",
    "def getFilePath():\n",
    "    model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    \n",
    "    if not os.path.exists(model_name):\n",
    "        os.mkdir(model_name)\n",
    "        \n",
    "    return model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
    "\n",
    "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, verbose=1)\n",
    "earlystop = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `steps_per_epoch` and `validation_steps` are used by `fit` method to decide the number of next() calls it need to make."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (num_train_sequences%batch_size) == 0:\n",
    "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
    "else:\n",
    "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
    "\n",
    "if (num_val_sequences%batch_size) == 0:\n",
    "    validation_steps = int(num_val_sequences/batch_size)\n",
    "else:\n",
    "    validation_steps = (num_val_sequences//batch_size) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN+RNN Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# epochs = 30\n"
     ]
    }
   ],
   "source": [
    "optimiser='sgd'\n",
    "num_epochs = 30\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential()\n",
    "\n",
    "rnn_model.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),input_shape=(15, 120, 120, 3)))\n",
    "rnn_model.add(TimeDistributed(BatchNormalization()))\n",
    "rnn_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "rnn_model.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "rnn_model.add(TimeDistributed(BatchNormalization()))\n",
    "rnn_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "rnn_model.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "rnn_model.add(TimeDistributed(BatchNormalization()))\n",
    "rnn_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "rnn_model.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "rnn_model.add(TimeDistributed(BatchNormalization()))\n",
    "rnn_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "rnn_model.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
    "rnn_model.add(TimeDistributed(BatchNormalization()))\n",
    "rnn_model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "rnn_model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "rnn_model.add(GRU(256))\n",
    "        \n",
    "rnn_model.add(Dense(128,activation='relu'))\n",
    "rnn_model.add(Dropout(0.5))\n",
    "\n",
    "rnn_model.add(Dense(64,activation='relu'))\n",
    "rnn_model.add(Dropout(0.25))\n",
    "rnn_model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_32 (TimeDis (None, 15, 120, 120, 16)  448       \n",
      "_________________________________________________________________\n",
      "time_distributed_33 (TimeDis (None, 15, 120, 120, 16)  64        \n",
      "_________________________________________________________________\n",
      "time_distributed_34 (TimeDis (None, 15, 60, 60, 16)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_35 (TimeDis (None, 15, 60, 60, 32)    4640      \n",
      "_________________________________________________________________\n",
      "time_distributed_36 (TimeDis (None, 15, 60, 60, 32)    128       \n",
      "_________________________________________________________________\n",
      "time_distributed_37 (TimeDis (None, 15, 30, 30, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_38 (TimeDis (None, 15, 30, 30, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_39 (TimeDis (None, 15, 30, 30, 64)    256       \n",
      "_________________________________________________________________\n",
      "time_distributed_40 (TimeDis (None, 15, 15, 15, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_41 (TimeDis (None, 15, 15, 15, 128)   73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_42 (TimeDis (None, 15, 15, 15, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_43 (TimeDis (None, 15, 7, 7, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_44 (TimeDis (None, 15, 7, 7, 256)     295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_45 (TimeDis (None, 15, 7, 7, 256)     1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_46 (TimeDis (None, 15, 3, 3, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_47 (TimeDis (None, 15, 2304)          0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 256)               1967616   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 2,403,685\n",
      "Trainable params: 2,402,693\n",
      "Non-trainable params: 992\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "rnn_model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (rnn_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.6290 - categorical_accuracy: 0.2760\n",
      "Epoch 00001: saving model to model_init_2021-08-0209_27_42.715839/model-00001-1.62901-0.27602-1.97272-0.19000.h5\n",
      "23/23 [==============================] - 137s 6s/step - loss: 1.6290 - categorical_accuracy: 0.2760 - val_loss: 1.9727 - val_categorical_accuracy: 0.1900\n",
      "Epoch 2/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.3080 - categorical_accuracy: 0.4359\n",
      "Epoch 00002: saving model to model_init_2021-08-0209_27_42.715839/model-00002-1.30799-0.43590-1.93535-0.25000.h5\n",
      "23/23 [==============================] - 138s 6s/step - loss: 1.3080 - categorical_accuracy: 0.4359 - val_loss: 1.9354 - val_categorical_accuracy: 0.2500\n",
      "Epoch 3/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.1852 - categorical_accuracy: 0.5083\n",
      "Epoch 00003: saving model to model_init_2021-08-0209_27_42.715839/model-00003-1.18518-0.50830-1.83234-0.25000.h5\n",
      "23/23 [==============================] - 132s 6s/step - loss: 1.1852 - categorical_accuracy: 0.5083 - val_loss: 1.8323 - val_categorical_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.0613 - categorical_accuracy: 0.5897\n",
      "Epoch 00004: saving model to model_init_2021-08-0209_27_42.715839/model-00004-1.06132-0.58974-1.57236-0.30000.h5\n",
      "23/23 [==============================] - 145s 6s/step - loss: 1.0613 - categorical_accuracy: 0.5897 - val_loss: 1.5724 - val_categorical_accuracy: 0.3000\n",
      "Epoch 5/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.9744 - categorical_accuracy: 0.6259\n",
      "Epoch 00005: saving model to model_init_2021-08-0209_27_42.715839/model-00005-0.97439-0.62594-1.20952-0.59000.h5\n",
      "23/23 [==============================] - 135s 6s/step - loss: 0.9744 - categorical_accuracy: 0.6259 - val_loss: 1.2095 - val_categorical_accuracy: 0.5900\n",
      "Epoch 6/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.8399 - categorical_accuracy: 0.6968\n",
      "Epoch 00006: saving model to model_init_2021-08-0209_27_42.715839/model-00006-0.83993-0.69683-1.39775-0.45000.h5\n",
      "23/23 [==============================] - 136s 6s/step - loss: 0.8399 - categorical_accuracy: 0.6968 - val_loss: 1.3978 - val_categorical_accuracy: 0.4500\n",
      "Epoch 7/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.7901 - categorical_accuracy: 0.6893\n",
      "Epoch 00007: saving model to model_init_2021-08-0209_27_42.715839/model-00007-0.79008-0.68929-1.65005-0.39000.h5\n",
      "23/23 [==============================] - 127s 6s/step - loss: 0.7901 - categorical_accuracy: 0.6893 - val_loss: 1.6500 - val_categorical_accuracy: 0.3900\n",
      "Epoch 8/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6835 - categorical_accuracy: 0.7632\n",
      "Epoch 00008: saving model to model_init_2021-08-0209_27_42.715839/model-00008-0.68352-0.76320-1.73587-0.31000.h5\n",
      "23/23 [==============================] - 128s 6s/step - loss: 0.6835 - categorical_accuracy: 0.7632 - val_loss: 1.7359 - val_categorical_accuracy: 0.3100\n",
      "Epoch 9/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6089 - categorical_accuracy: 0.7587\n",
      "Epoch 00009: saving model to model_init_2021-08-0209_27_42.715839/model-00009-0.60888-0.75867-1.36404-0.57000.h5\n",
      "23/23 [==============================] - 99s 4s/step - loss: 0.6089 - categorical_accuracy: 0.7587 - val_loss: 1.3640 - val_categorical_accuracy: 0.5700\n",
      "Epoch 10/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5310 - categorical_accuracy: 0.8265\n",
      "Epoch 00010: saving model to model_init_2021-08-0209_27_42.715839/model-00010-0.53104-0.82655-1.07356-0.62000.h5\n",
      "23/23 [==============================] - 93s 4s/step - loss: 0.5310 - categorical_accuracy: 0.8265 - val_loss: 1.0736 - val_categorical_accuracy: 0.6200\n",
      "Epoch 11/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5327 - categorical_accuracy: 0.8069\n",
      "Epoch 00011: saving model to model_init_2021-08-0209_27_42.715839/model-00011-0.53270-0.80694-0.81616-0.70000.h5\n",
      "23/23 [==============================] - 99s 4s/step - loss: 0.5327 - categorical_accuracy: 0.8069 - val_loss: 0.8162 - val_categorical_accuracy: 0.7000\n",
      "Epoch 12/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.3667 - categorical_accuracy: 0.8824\n",
      "Epoch 00012: saving model to model_init_2021-08-0209_27_42.715839/model-00012-0.36671-0.88235-0.70915-0.73000.h5\n",
      "23/23 [==============================] - 100s 4s/step - loss: 0.3667 - categorical_accuracy: 0.8824 - val_loss: 0.7091 - val_categorical_accuracy: 0.7300\n",
      "Epoch 13/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.3293 - categorical_accuracy: 0.8944\n",
      "Epoch 00013: saving model to model_init_2021-08-0209_27_42.715839/model-00013-0.32929-0.89442-0.66812-0.76000.h5\n",
      "23/23 [==============================] - 99s 4s/step - loss: 0.3293 - categorical_accuracy: 0.8944 - val_loss: 0.6681 - val_categorical_accuracy: 0.7600\n",
      "Epoch 14/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.3117 - categorical_accuracy: 0.8974\n",
      "Epoch 00014: saving model to model_init_2021-08-0209_27_42.715839/model-00014-0.31171-0.89744-1.29112-0.61000.h5\n",
      "23/23 [==============================] - 94s 4s/step - loss: 0.3117 - categorical_accuracy: 0.8974 - val_loss: 1.2911 - val_categorical_accuracy: 0.6100\n",
      "Epoch 15/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4154 - categorical_accuracy: 0.8718\n",
      "Epoch 00015: saving model to model_init_2021-08-0209_27_42.715839/model-00015-0.41535-0.87179-0.80772-0.72000.h5\n",
      "23/23 [==============================] - 101s 4s/step - loss: 0.4154 - categorical_accuracy: 0.8718 - val_loss: 0.8077 - val_categorical_accuracy: 0.7200\n",
      "Epoch 16/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.3155 - categorical_accuracy: 0.9020\n",
      "Epoch 00016: saving model to model_init_2021-08-0209_27_42.715839/model-00016-0.31551-0.90196-0.84252-0.69000.h5\n",
      "23/23 [==============================] - 107s 5s/step - loss: 0.3155 - categorical_accuracy: 0.9020 - val_loss: 0.8425 - val_categorical_accuracy: 0.6900\n",
      "Epoch 17/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2846 - categorical_accuracy: 0.8989\n",
      "Epoch 00017: saving model to model_init_2021-08-0209_27_42.715839/model-00017-0.28465-0.89894-0.71193-0.79000.h5\n",
      "23/23 [==============================] - 97s 4s/step - loss: 0.2846 - categorical_accuracy: 0.8989 - val_loss: 0.7119 - val_categorical_accuracy: 0.7900\n",
      "Epoch 18/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2050 - categorical_accuracy: 0.9367\n",
      "Epoch 00018: saving model to model_init_2021-08-0209_27_42.715839/model-00018-0.20500-0.93665-0.73610-0.78000.h5\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "23/23 [==============================] - 94s 4s/step - loss: 0.2050 - categorical_accuracy: 0.9367 - val_loss: 0.7361 - val_categorical_accuracy: 0.7800\n",
      "Epoch 19/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1667 - categorical_accuracy: 0.9548\n",
      "Epoch 00019: saving model to model_init_2021-08-0209_27_42.715839/model-00019-0.16671-0.95475-0.65311-0.80000.h5\n",
      "23/23 [==============================] - 101s 4s/step - loss: 0.1667 - categorical_accuracy: 0.9548 - val_loss: 0.6531 - val_categorical_accuracy: 0.8000\n",
      "Epoch 20/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1681 - categorical_accuracy: 0.9548\n",
      "Epoch 00020: saving model to model_init_2021-08-0209_27_42.715839/model-00020-0.16810-0.95475-0.62439-0.82000.h5\n",
      "23/23 [==============================] - 103s 4s/step - loss: 0.1681 - categorical_accuracy: 0.9548 - val_loss: 0.6244 - val_categorical_accuracy: 0.8200\n",
      "Epoch 21/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1692 - categorical_accuracy: 0.9502\n",
      "Epoch 00021: saving model to model_init_2021-08-0209_27_42.715839/model-00021-0.16925-0.95023-0.53659-0.83000.h5\n",
      "23/23 [==============================] - 87s 4s/step - loss: 0.1692 - categorical_accuracy: 0.9502 - val_loss: 0.5366 - val_categorical_accuracy: 0.8300\n",
      "Epoch 22/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1446 - categorical_accuracy: 0.9623\n",
      "Epoch 00022: saving model to model_init_2021-08-0209_27_42.715839/model-00022-0.14463-0.96229-0.66912-0.82000.h5\n",
      "23/23 [==============================] - 83s 4s/step - loss: 0.1446 - categorical_accuracy: 0.9623 - val_loss: 0.6691 - val_categorical_accuracy: 0.8200\n",
      "Epoch 23/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1305 - categorical_accuracy: 0.9729\n",
      "Epoch 00023: saving model to model_init_2021-08-0209_27_42.715839/model-00023-0.13053-0.97285-0.66018-0.81000.h5\n",
      "23/23 [==============================] - 86s 4s/step - loss: 0.1305 - categorical_accuracy: 0.9729 - val_loss: 0.6602 - val_categorical_accuracy: 0.8100\n",
      "Epoch 24/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1426 - categorical_accuracy: 0.9608\n",
      "Epoch 00024: saving model to model_init_2021-08-0209_27_42.715839/model-00024-0.14263-0.96078-0.65131-0.82000.h5\n",
      "23/23 [==============================] - 87s 4s/step - loss: 0.1426 - categorical_accuracy: 0.9608 - val_loss: 0.6513 - val_categorical_accuracy: 0.8200\n",
      "Epoch 25/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1199 - categorical_accuracy: 0.9653\n",
      "Epoch 00025: saving model to model_init_2021-08-0209_27_42.715839/model-00025-0.11991-0.96531-0.72027-0.79000.h5\n",
      "23/23 [==============================] - 89s 4s/step - loss: 0.1199 - categorical_accuracy: 0.9653 - val_loss: 0.7203 - val_categorical_accuracy: 0.7900\n",
      "Epoch 26/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1271 - categorical_accuracy: 0.9759\n",
      "Epoch 00026: saving model to model_init_2021-08-0209_27_42.715839/model-00026-0.12708-0.97587-0.61467-0.79000.h5\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "23/23 [==============================] - 85s 4s/step - loss: 0.1271 - categorical_accuracy: 0.9759 - val_loss: 0.6147 - val_categorical_accuracy: 0.7900\n",
      "Epoch 27/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1115 - categorical_accuracy: 0.9789\n",
      "Epoch 00027: saving model to model_init_2021-08-0209_27_42.715839/model-00027-0.11154-0.97888-0.62410-0.78000.h5\n",
      "23/23 [==============================] - 89s 4s/step - loss: 0.1115 - categorical_accuracy: 0.9789 - val_loss: 0.6241 - val_categorical_accuracy: 0.7800\n",
      "Epoch 28/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1412 - categorical_accuracy: 0.9623\n",
      "Epoch 00028: saving model to model_init_2021-08-0209_27_42.715839/model-00028-0.14119-0.96229-0.64964-0.76000.h5\n",
      "23/23 [==============================] - 89s 4s/step - loss: 0.1412 - categorical_accuracy: 0.9623 - val_loss: 0.6496 - val_categorical_accuracy: 0.7600\n",
      "Epoch 29/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1071 - categorical_accuracy: 0.9804\n",
      "Epoch 00029: saving model to model_init_2021-08-0209_27_42.715839/model-00029-0.10713-0.98039-0.71571-0.75000.h5\n",
      "23/23 [==============================] - 89s 4s/step - loss: 0.1071 - categorical_accuracy: 0.9804 - val_loss: 0.7157 - val_categorical_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1004 - categorical_accuracy: 0.9774\n",
      "Epoch 00030: saving model to model_init_2021-08-0209_27_42.715839/model-00030-0.10035-0.97738-0.59200-0.81000.h5\n",
      "23/23 [==============================] - 88s 4s/step - loss: 0.1004 - categorical_accuracy: 0.9774 - val_loss: 0.5920 - val_categorical_accuracy: 0.8100\n"
     ]
    }
   ],
   "source": [
    "history_rnn = rnn_model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(history_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv3D Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtersize=(3,3,3)\n",
    "dense_neurons=256\n",
    "\n",
    "conv3d_model = Sequential()\n",
    "conv3d_model.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "conv3d_model.add(Activation('relu'))\n",
    "conv3d_model.add(BatchNormalization())\n",
    "\n",
    "conv3d_model.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "conv3d_model.add(Activation('relu'))\n",
    "conv3d_model.add(BatchNormalization())\n",
    "\n",
    "conv3d_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "conv3d_model.add(Conv3D(64, filtersize, padding='same'))\n",
    "conv3d_model.add(Activation('relu'))\n",
    "conv3d_model.add(BatchNormalization())\n",
    "\n",
    "conv3d_model.add(Conv3D(64, filtersize, padding='same'))\n",
    "conv3d_model.add(Activation('relu'))\n",
    "conv3d_model.add(BatchNormalization())\n",
    "\n",
    "conv3d_model.add(Conv3D(64, filtersize, padding='same'))\n",
    "conv3d_model.add(Activation('relu'))\n",
    "conv3d_model.add(BatchNormalization())\n",
    "\n",
    "conv3d_model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "conv3d_model.add(Flatten())\n",
    "conv3d_model.add(Dense(dense_neurons,activation='relu'))\n",
    "conv3d_model.add(BatchNormalization())\n",
    "conv3d_model.add(Dropout(0.25))\n",
    "\n",
    "conv3d_model.add(Dense(dense_neurons,activation='relu'))\n",
    "conv3d_model.add(BatchNormalization())\n",
    "conv3d_model.add(Dropout(0.25))\n",
    "\n",
    "conv3d_model.add(Dense(num_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv3d_6 (Conv3D)            (None, 15, 120, 120, 32)  2624      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 15, 120, 120, 32)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 15, 120, 120, 32)  128       \n",
      "_________________________________________________________________\n",
      "conv3d_7 (Conv3D)            (None, 15, 120, 120, 32)  27680     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 15, 120, 120, 32)  0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 15, 120, 120, 32)  128       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_3 (MaxPooling3 (None, 7, 60, 60, 32)     0         \n",
      "_________________________________________________________________\n",
      "conv3d_8 (Conv3D)            (None, 7, 60, 60, 64)     55360     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 7, 60, 60, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 7, 60, 60, 64)     256       \n",
      "_________________________________________________________________\n",
      "conv3d_9 (Conv3D)            (None, 7, 60, 60, 64)     110656    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 7, 60, 60, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 7, 60, 60, 64)     256       \n",
      "_________________________________________________________________\n",
      "conv3d_10 (Conv3D)           (None, 7, 60, 60, 64)     110656    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 7, 60, 60, 64)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 7, 60, 60, 64)     256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_4 (MaxPooling3 (None, 3, 30, 30, 64)     0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 172800)            0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               44237056  \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 44,614,181\n",
      "Trainable params: 44,612,645\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "conv3d_model.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (conv3d_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source path =  /home/datasets/Project_data/train ; batch size = 30\n",
      "Epoch 1/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 1.4119 - categorical_accuracy: 0.4977Source path =  /home/datasets/Project_data/val ; batch size = 30\n",
      "\n",
      "Epoch 00001: saving model to model_init_2021-08-0208_17_46.514952/model-00001-1.41188-0.49774-141.78842-0.23000.h5\n",
      "23/23 [==============================] - 90s 4s/step - loss: 1.4119 - categorical_accuracy: 0.4977 - val_loss: 141.7884 - val_categorical_accuracy: 0.2300\n",
      "Epoch 2/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.9164 - categorical_accuracy: 0.6772\n",
      "Epoch 00002: saving model to model_init_2021-08-0208_17_46.514952/model-00002-0.91636-0.67722-80.29002-0.20000.h5\n",
      "23/23 [==============================] - 92s 4s/step - loss: 0.9164 - categorical_accuracy: 0.6772 - val_loss: 80.2900 - val_categorical_accuracy: 0.2000\n",
      "Epoch 3/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.7333 - categorical_accuracy: 0.7360\n",
      "Epoch 00003: saving model to model_init_2021-08-0208_17_46.514952/model-00003-0.73327-0.73605-35.54998-0.25000.h5\n",
      "23/23 [==============================] - 91s 4s/step - loss: 0.7333 - categorical_accuracy: 0.7360 - val_loss: 35.5500 - val_categorical_accuracy: 0.2500\n",
      "Epoch 4/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6717 - categorical_accuracy: 0.7496\n",
      "Epoch 00004: saving model to model_init_2021-08-0208_17_46.514952/model-00004-0.67167-0.74962-70.18033-0.22000.h5\n",
      "23/23 [==============================] - 89s 4s/step - loss: 0.6717 - categorical_accuracy: 0.7496 - val_loss: 70.1803 - val_categorical_accuracy: 0.2200\n",
      "Epoch 5/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5433 - categorical_accuracy: 0.8039\n",
      "Epoch 00005: saving model to model_init_2021-08-0208_17_46.514952/model-00005-0.54332-0.80392-23.41523-0.24000.h5\n",
      "23/23 [==============================] - 91s 4s/step - loss: 0.5433 - categorical_accuracy: 0.8039 - val_loss: 23.4152 - val_categorical_accuracy: 0.2400\n",
      "Epoch 6/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.4623 - categorical_accuracy: 0.8205\n",
      "Epoch 00006: saving model to model_init_2021-08-0208_17_46.514952/model-00006-0.46231-0.82051-13.65134-0.27000.h5\n",
      "23/23 [==============================] - 91s 4s/step - loss: 0.4623 - categorical_accuracy: 0.8205 - val_loss: 13.6513 - val_categorical_accuracy: 0.2700\n",
      "Epoch 7/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.3296 - categorical_accuracy: 0.8763\n",
      "Epoch 00007: saving model to model_init_2021-08-0208_17_46.514952/model-00007-0.32959-0.87632-8.24724-0.32000.h5\n",
      "23/23 [==============================] - 91s 4s/step - loss: 0.3296 - categorical_accuracy: 0.8763 - val_loss: 8.2472 - val_categorical_accuracy: 0.3200\n",
      "Epoch 8/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2851 - categorical_accuracy: 0.8929\n",
      "Epoch 00008: saving model to model_init_2021-08-0208_17_46.514952/model-00008-0.28513-0.89291-4.14339-0.42000.h5\n",
      "23/23 [==============================] - 89s 4s/step - loss: 0.2851 - categorical_accuracy: 0.8929 - val_loss: 4.1434 - val_categorical_accuracy: 0.4200\n",
      "Epoch 9/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2418 - categorical_accuracy: 0.9155\n",
      "Epoch 00009: saving model to model_init_2021-08-0208_17_46.514952/model-00009-0.24176-0.91554-5.50322-0.40000.h5\n",
      "23/23 [==============================] - 92s 4s/step - loss: 0.2418 - categorical_accuracy: 0.9155 - val_loss: 5.5032 - val_categorical_accuracy: 0.4000\n",
      "Epoch 10/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2322 - categorical_accuracy: 0.9231\n",
      "Epoch 00010: saving model to model_init_2021-08-0208_17_46.514952/model-00010-0.23217-0.92308-3.36659-0.37000.h5\n",
      "23/23 [==============================] - 91s 4s/step - loss: 0.2322 - categorical_accuracy: 0.9231 - val_loss: 3.3666 - val_categorical_accuracy: 0.3700\n",
      "Epoch 11/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.6752 - categorical_accuracy: 0.7496\n",
      "Epoch 00011: saving model to model_init_2021-08-0208_17_46.514952/model-00011-0.67522-0.74962-48.66660-0.25000.h5\n",
      "23/23 [==============================] - 91s 4s/step - loss: 0.6752 - categorical_accuracy: 0.7496 - val_loss: 48.6666 - val_categorical_accuracy: 0.2500\n",
      "Epoch 12/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5487 - categorical_accuracy: 0.7994\n",
      "Epoch 00012: saving model to model_init_2021-08-0208_17_46.514952/model-00012-0.54869-0.79940-62.55519-0.25000.h5\n",
      "23/23 [==============================] - 86s 4s/step - loss: 0.5487 - categorical_accuracy: 0.7994 - val_loss: 62.5552 - val_categorical_accuracy: 0.2500\n",
      "Epoch 13/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2766 - categorical_accuracy: 0.9125\n",
      "Epoch 00013: saving model to model_init_2021-08-0208_17_46.514952/model-00013-0.27657-0.91252-18.77366-0.32000.h5\n",
      "23/23 [==============================] - 87s 4s/step - loss: 0.2766 - categorical_accuracy: 0.9125 - val_loss: 18.7737 - val_categorical_accuracy: 0.3200\n",
      "Epoch 14/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.5253 - categorical_accuracy: 0.8220\n",
      "Epoch 00014: saving model to model_init_2021-08-0208_17_46.514952/model-00014-0.52530-0.82202-8.66958-0.41000.h5\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "23/23 [==============================] - 87s 4s/step - loss: 0.5253 - categorical_accuracy: 0.8220 - val_loss: 8.6696 - val_categorical_accuracy: 0.4100\n",
      "Epoch 15/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.3070 - categorical_accuracy: 0.8869\n",
      "Epoch 00015: saving model to model_init_2021-08-0208_17_46.514952/model-00015-0.30704-0.88688-6.75205-0.34000.h5\n",
      "23/23 [==============================] - 89s 4s/step - loss: 0.3070 - categorical_accuracy: 0.8869 - val_loss: 6.7521 - val_categorical_accuracy: 0.3400\n",
      "Epoch 16/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2565 - categorical_accuracy: 0.9065\n",
      "Epoch 00016: saving model to model_init_2021-08-0208_17_46.514952/model-00016-0.25650-0.90649-5.28167-0.43000.h5\n",
      "23/23 [==============================] - 85s 4s/step - loss: 0.2565 - categorical_accuracy: 0.9065 - val_loss: 5.2817 - val_categorical_accuracy: 0.4300\n",
      "Epoch 17/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.2213 - categorical_accuracy: 0.9231\n",
      "Epoch 00017: saving model to model_init_2021-08-0208_17_46.514952/model-00017-0.22127-0.92308-2.57633-0.55000.h5\n",
      "23/23 [==============================] - 87s 4s/step - loss: 0.2213 - categorical_accuracy: 0.9231 - val_loss: 2.5763 - val_categorical_accuracy: 0.5500\n",
      "Epoch 18/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1861 - categorical_accuracy: 0.9367\n",
      "Epoch 00018: saving model to model_init_2021-08-0208_17_46.514952/model-00018-0.18608-0.93665-1.34211-0.61000.h5\n",
      "23/23 [==============================] - 87s 4s/step - loss: 0.1861 - categorical_accuracy: 0.9367 - val_loss: 1.3421 - val_categorical_accuracy: 0.6100\n",
      "Epoch 19/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1538 - categorical_accuracy: 0.9608\n",
      "Epoch 00019: saving model to model_init_2021-08-0208_17_46.514952/model-00019-0.15381-0.96078-1.34464-0.61000.h5\n",
      "23/23 [==============================] - 88s 4s/step - loss: 0.1538 - categorical_accuracy: 0.9608 - val_loss: 1.3446 - val_categorical_accuracy: 0.6100\n",
      "Epoch 20/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1434 - categorical_accuracy: 0.9487\n",
      "Epoch 00020: saving model to model_init_2021-08-0208_17_46.514952/model-00020-0.14343-0.94872-0.87593-0.73000.h5\n",
      "23/23 [==============================] - 87s 4s/step - loss: 0.1434 - categorical_accuracy: 0.9487 - val_loss: 0.8759 - val_categorical_accuracy: 0.7300\n",
      "Epoch 21/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1313 - categorical_accuracy: 0.9668\n",
      "Epoch 00021: saving model to model_init_2021-08-0208_17_46.514952/model-00021-0.13130-0.96682-0.82561-0.71000.h5\n",
      "23/23 [==============================] - 92s 4s/step - loss: 0.1313 - categorical_accuracy: 0.9668 - val_loss: 0.8256 - val_categorical_accuracy: 0.7100\n",
      "Epoch 22/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1480 - categorical_accuracy: 0.9472\n",
      "Epoch 00022: saving model to model_init_2021-08-0208_17_46.514952/model-00022-0.14799-0.94721-0.73098-0.75000.h5\n",
      "23/23 [==============================] - 94s 4s/step - loss: 0.1480 - categorical_accuracy: 0.9472 - val_loss: 0.7310 - val_categorical_accuracy: 0.7500\n",
      "Epoch 23/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1381 - categorical_accuracy: 0.9578\n",
      "Epoch 00023: saving model to model_init_2021-08-0208_17_46.514952/model-00023-0.13812-0.95777-0.47352-0.82000.h5\n",
      "23/23 [==============================] - 91s 4s/step - loss: 0.1381 - categorical_accuracy: 0.9578 - val_loss: 0.4735 - val_categorical_accuracy: 0.8200\n",
      "Epoch 24/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1200 - categorical_accuracy: 0.9623\n",
      "Epoch 00024: saving model to model_init_2021-08-0208_17_46.514952/model-00024-0.12003-0.96229-0.52373-0.81000.h5\n",
      "23/23 [==============================] - 88s 4s/step - loss: 0.1200 - categorical_accuracy: 0.9623 - val_loss: 0.5237 - val_categorical_accuracy: 0.8100\n",
      "Epoch 25/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1020 - categorical_accuracy: 0.9729\n",
      "Epoch 00025: saving model to model_init_2021-08-0208_17_46.514952/model-00025-0.10204-0.97285-0.48461-0.80000.h5\n",
      "23/23 [==============================] - 92s 4s/step - loss: 0.1020 - categorical_accuracy: 0.9729 - val_loss: 0.4846 - val_categorical_accuracy: 0.8000\n",
      "Epoch 26/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.1239 - categorical_accuracy: 0.9563\n",
      "Epoch 00026: saving model to model_init_2021-08-0208_17_46.514952/model-00026-0.12387-0.95626-0.47266-0.83000.h5\n",
      "23/23 [==============================] - 91s 4s/step - loss: 0.1239 - categorical_accuracy: 0.9563 - val_loss: 0.4727 - val_categorical_accuracy: 0.8300\n",
      "Epoch 27/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0756 - categorical_accuracy: 0.9849\n",
      "Epoch 00027: saving model to model_init_2021-08-0208_17_46.514952/model-00027-0.07560-0.98492-0.47178-0.84000.h5\n",
      "23/23 [==============================] - 92s 4s/step - loss: 0.0756 - categorical_accuracy: 0.9849 - val_loss: 0.4718 - val_categorical_accuracy: 0.8400\n",
      "Epoch 28/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0834 - categorical_accuracy: 0.9713\n",
      "Epoch 00028: saving model to model_init_2021-08-0208_17_46.514952/model-00028-0.08336-0.97134-0.48996-0.83000.h5\n",
      "23/23 [==============================] - 89s 4s/step - loss: 0.0834 - categorical_accuracy: 0.9713 - val_loss: 0.4900 - val_categorical_accuracy: 0.8300\n",
      "Epoch 29/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0774 - categorical_accuracy: 0.9744\n",
      "Epoch 00029: saving model to model_init_2021-08-0208_17_46.514952/model-00029-0.07739-0.97436-0.50509-0.82000.h5\n",
      "23/23 [==============================] - 91s 4s/step - loss: 0.0774 - categorical_accuracy: 0.9744 - val_loss: 0.5051 - val_categorical_accuracy: 0.8200\n",
      "Epoch 30/30\n",
      "23/23 [==============================] - ETA: 0s - loss: 0.0733 - categorical_accuracy: 0.9864\n",
      "Epoch 00030: saving model to model_init_2021-08-0208_17_46.514952/model-00030-0.07331-0.98643-0.39173-0.83000.h5\n",
      "23/23 [==============================] - 92s 4s/step - loss: 0.0733 - categorical_accuracy: 0.9864 - val_loss: 0.3917 - val_categorical_accuracy: 0.8300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f36ad532048>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv3d_model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "This section contains all the models built as a part of the exploration process. The final models for each of RNN and Conv3D approch are the ones highlighted above. For testing different models, we've used 15 epochs for faster training purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: CNN+RNN Single Layer with 15 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "\n",
    "model_1.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu'),input_shape=(15, 120, 120, 3)))\n",
    "model_1.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model_1.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_1.add(GRU(32))\n",
    "        \n",
    "model_1.add(Dense(128,activation='relu'))\n",
    "model_1.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have written the model, the next step is to `compile` the model. When you print the `summary` of the model, you'll see the total number of parameters you have to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = 'Adam' # Let's test with Adam first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, LR]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit the model. This will start training the model and with the help of the checkpoints, you'll be able to save the model at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can clearly see, the model is very much underfitting and performs only as good as a naive model. Let's try to add more layers to the model and see if that helps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Two layers CNN+RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "\n",
    "model_2.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),input_shape=(15, 120, 120, 3)))\n",
    "model_2.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_2.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model_2.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model_2.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_2.add(GRU(32))\n",
    "        \n",
    "model_2.add(Dense(128,activation='relu'))\n",
    "model_2.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Two layers CNN+RNN+Batch Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "\n",
    "model_3.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),input_shape=(15, 120, 120, 3)))\n",
    "model_3.add(TimeDistributed(BatchNormalization()))\n",
    "model_3.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_3.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model_3.add(TimeDistributed(BatchNormalization()))\n",
    "model_3.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model_3.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_3.add(GRU(32))\n",
    "        \n",
    "model_3.add(Dense(128,activation='relu'))\n",
    "model_3.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_3 = model_3.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding batch normalisation has proven to improve the accuracy by a huge margin and this is mainly due to the fact that there would be a huge deviation in the data and normalising helps in closing that gap. But we can see that now the model has overfitted on the training data, since there's a huge gap of over 25% between the training and validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Two layers CNN+RNN+Batch Normalisation+Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Sequential()\n",
    "\n",
    "model_4.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),input_shape=(15, 120, 120, 3)))\n",
    "model_4.add(TimeDistributed(BatchNormalization()))\n",
    "model_4.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_4.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model_4.add(TimeDistributed(BatchNormalization()))\n",
    "model_4.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model_4.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_4.add(GRU(32))\n",
    "        \n",
    "model_4.add(Dense(128,activation='relu'))\n",
    "model_4.add(Dropout(0.25))\n",
    "model_4.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4 = model_4.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding dropout has reduced the overfitting to an extent, but as a side effect, the model seems to have not adapted well to both the train and test data. We will now try out the same model with SGD optimiser to see if changing the optimiser has any effect on the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Two layers CNN+RNN+Batch Normalisation+Dropout (SGD Optimiser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = Sequential()\n",
    "\n",
    "model_5.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),input_shape=(15, 120, 120, 3)))\n",
    "model_5.add(TimeDistributed(BatchNormalization()))\n",
    "model_5.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_5.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model_5.add(TimeDistributed(BatchNormalization()))\n",
    "model_5.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model_5.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_5.add(GRU(32))\n",
    "        \n",
    "model_5.add(Dense(128,activation='relu'))\n",
    "model_5.add(Dropout(0.25))\n",
    "model_5.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5 = model_5.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD seems to perform better, even though there's a slight overfitting. Let us try increasing the complexity of the model and add dropouts to reduce this. Also we can see that even after 15 epochs, the model is still growing, so running with more no. of epochs might give us better results on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 6: Multi Layer CNN+RNN+Batch Normalisation+Dropout (fully packed model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser='sgd'\n",
    "num_epochs = 30\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = Sequential()\n",
    "\n",
    "model_6.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),input_shape=(15, 120, 120, 3)))\n",
    "model_6.add(TimeDistributed(BatchNormalization()))\n",
    "model_6.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_6.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model_6.add(TimeDistributed(BatchNormalization()))\n",
    "model_6.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_6.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "model_6.add(TimeDistributed(BatchNormalization()))\n",
    "model_6.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_6.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "model_6.add(TimeDistributed(BatchNormalization()))\n",
    "model_6.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_6.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
    "model_6.add(TimeDistributed(BatchNormalization()))\n",
    "model_6.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model_6.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_6.add(GRU(256))\n",
    "        \n",
    "model_6.add(Dense(128,activation='relu'))\n",
    "model_6.add(Dropout(0.25))\n",
    "\n",
    "model_6.add(Dense(64,activation='relu'))\n",
    "model_6.add(Dropout(0.25))\n",
    "model_6.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_6 = model_6.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model fits overall really well but still is overfitting on the training data. Let's try increasing the dropout a bit to see if that helps in avoiding this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can clearly see from the graph, the overfitting has been reduced a bit compared to the previous model. Even though it is still highly inclined towards train data, it generalises comparatively better to the previous one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 7: Multi Layer CNN+RNN+Batch Normalisation+Increased Dropout (fully packed model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = Sequential()\n",
    "\n",
    "model_7.add(TimeDistributed(Conv2D(16, (3, 3) , padding='same', activation='relu'),input_shape=(15, 120, 120, 3)))\n",
    "model_7.add(TimeDistributed(BatchNormalization()))\n",
    "model_7.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_7.add(TimeDistributed(Conv2D(32, (3, 3) , padding='same', activation='relu')))\n",
    "model_7.add(TimeDistributed(BatchNormalization()))\n",
    "model_7.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_7.add(TimeDistributed(Conv2D(64, (3, 3) , padding='same', activation='relu')))\n",
    "model_7.add(TimeDistributed(BatchNormalization()))\n",
    "model_7.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_7.add(TimeDistributed(Conv2D(128, (3, 3) , padding='same', activation='relu')))\n",
    "model_7.add(TimeDistributed(BatchNormalization()))\n",
    "model_7.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "\n",
    "model_7.add(TimeDistributed(Conv2D(256, (3, 3) , padding='same', activation='relu')))\n",
    "model_7.add(TimeDistributed(BatchNormalization()))\n",
    "model_7.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model_7.add(TimeDistributed(Flatten()))\n",
    "\n",
    "model_7.add(GRU(256))\n",
    "        \n",
    "model_7.add(Dense(128,activation='relu'))\n",
    "model_7.add(Dropout(0.5))\n",
    "\n",
    "model_7.add(Dense(64,activation='relu'))\n",
    "model_7.add(Dropout(0.25))\n",
    "model_7.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_7.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_7 = model_7.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(history_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tried out various models using CNN+RNN stack, let's now try out Convolution 3D models to see if they help in avoiding overfitting or getting overall better output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Conv3D Single Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimiser = 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtersize=(3,3,3)\n",
    "dense_neurons=256\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "model_1.add(Activation('relu'))\n",
    "\n",
    "model_1.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_1.add(Flatten())\n",
    "model_1.add(Dense(dense_neurons,activation='relu'))\n",
    "\n",
    "model_1.add(Dense(num_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_1.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, earlystop, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_1 = model_1.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot(history_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Conv3D Two Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtersize=(3,3,3)\n",
    "dense_neurons=256\n",
    "\n",
    "model_2 = Sequential()\n",
    "model_2.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "model_2.add(Activation('relu'))\n",
    "\n",
    "model_2.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "model_2.add(Activation('relu'))\n",
    "\n",
    "model_2.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "\n",
    "model_2.add(Flatten())\n",
    "model_2.add(Dense(dense_neurons,activation='relu'))\n",
    "\n",
    "model_2.add(Dense(num_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_2 = model_2.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3:  Two Layers Conv3D+Batch Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtersize=(3,3,3)\n",
    "dense_neurons=256\n",
    "\n",
    "model_3 = Sequential()\n",
    "model_3.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "model_3.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "model_3.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "\n",
    "model_3.add(Flatten())\n",
    "model_3.add(Dense(dense_neurons,activation='relu'))\n",
    "model_3.add(BatchNormalization())\n",
    "\n",
    "model_3.add(Dense(num_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_3 = model_3.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here by adding batch normalization validation accuracy has increased significantly. However it has now completely overfitted on train data. Let's add dropouts to prevent the overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4:  Two Layers Conv3D+BatchNormalisation+Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtersize=(3,3,3)\n",
    "dense_neurons=256\n",
    "\n",
    "model_4 = Sequential()\n",
    "model_4.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "model_4.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "model_4.add(Activation('relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "\n",
    "model_4.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "model_4.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model_4.add(Flatten())\n",
    "model_4.add(Dense(dense_neurons,activation='relu'))\n",
    "model_4.add(BatchNormalization())\n",
    "model_4.add(Dropout(0.5))\n",
    "\n",
    "model_4.add(Dense(num_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_4 = model_4.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 5: Multi Layer Conv3D+Batch Normalisation+Dropout (fully packed model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "print ('# epochs =', num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtersize=(3,3,3)\n",
    "dense_neurons=256\n",
    "\n",
    "model_5 = Sequential()\n",
    "model_5.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "model_5.add(Conv3D(32, filtersize, padding='same',input_shape=(15,120,120,3)))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "model_5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "model_5.add(Conv3D(64, filtersize, padding='same'))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "model_5.add(Conv3D(64, filtersize, padding='same'))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "model_5.add(Conv3D(64, filtersize, padding='same'))\n",
    "model_5.add(Activation('relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "\n",
    "\n",
    "model_5.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
    "\n",
    "\n",
    "model_5.add(Flatten())\n",
    "model_5.add(Dense(dense_neurons,activation='relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Dropout(0.25))\n",
    "\n",
    "model_5.add(Dense(dense_neurons,activation='relu'))\n",
    "model_5.add(BatchNormalization())\n",
    "model_5.add(Dropout(0.25))\n",
    "\n",
    "model_5.add(Dense(num_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.compile(optimizer=optimiser, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "print (model_5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(getFilePath(), monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto',save_freq = 'epoch')\n",
    "\n",
    "callbacks_list = [checkpoint, LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_5 = model_5.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
    "                    callbacks=callbacks_list, validation_data=val_generator, \n",
    "                    validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(history_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
